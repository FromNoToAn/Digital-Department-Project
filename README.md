# API DEVELOPMENT
IIR NSU 2025, 3rd year, 22931-32 group members

# Документация по системе обнаружения целевых объектов (ядро/базовая версия)

## Содержание

  - [Обзор](#обзор)

    - [Введение](#введение)
    - [Цель](#цель)
    - [Необходимые программы для установки и работы](#необходимые-программы-для-установки-и-работы)
    - [Предварительные знания](#предварительные-знания)

  - [Разделы](#разделы)

    1. [Настройка окружения](#1-настройка-окружения)
    2. [Установка репозитория](#2-установка-репозитория)
    3. [Установка зависимостей](#3-установка-зависимостей)
    4. [Конфигурация системы](#4-конфигурация-системы)
        1. [Общая конфигурация через конфигурационный файл](#41-общая-конфигурация-через-конфигурационный-файл)
        2. [Общая конфигурация файла запуска детектора](#42-общая-конфигурация-файла-запуска-детектора)
        3. [Дополнительная конфигурация в файлах с кодом](#43-дополнительная-конфигурация-в-файлах-с-кодом)
        4. [Конфигурация логирования](#44-конфигурация-логирования)
    5. [Описание изначально пустых/несуществующих папок](#5-описание-изначально-пустыхнесуществующих-папок)
    6. [Docker контейнеризация](#6-docker-контейнеризация)
    7. [API взаимодействия](#7-api-взаимодействия)
        1. [Постановка задачи](#71-постановка-задачи)
        2. [Получение информации о задаче](#72-получение-информации-о-задаче)
        3. [Остановка задачи](#73-остановка-задачи)
    8. [Путь работы задачи](#8-путь-работы-задачи)

## Обзор

### Введение

  Эта документация предоставляет подробное описание ядра системы обнаружения объектов. Она предназначена для разработчиков, которые хотят понять как работает основа любой другой системы обнаружения целевых событий, основаная на этом ядре, настроить ее или создать собственную на ее основе.

  Существует несколько вариаций ядра системы обнаружения объектов:

  1. Общая версия ядра с api для внутреннего использования/тестирования на сервисе VAS-API, которая запускается при помощи onnxruntime (GPU/CPU).
  2. Общая версия ядра с api для внутреннего использования/тестирования на сервисе VAS-API, которая запускается при помощи openvino (CPU).
  3. Общая версия ядра с api для внутреннего использования/тестирования на сервисе VAS-API, которая запускается при помощи rknn-lite (OrangePi 5 NPU).

  Каждая из них находиться в своей ветке в репозитории: cuda, openvino, oragepi соответственно.

  Они все по умолчанию работают с/отправляют на VAS-API. Для того чтобы они взаимодействовали с сервисом ITX требуется произвести merge с нужной веткой. Есть три ветки, связанные с группами детекторов:

  - integration_anpr
  - integration_sa
  - integration_srvr

  То есть производим merge выбранного детектора, основанного на этом ядре, с нужной веткой в соответствии с его группой.

  Далее будет представлено описание по установке и настройке общей версии ядра системы обнаружения объектов (сервис VAS-API). С настройкой детекторов для интеграции с сервисом ITX можно ознакомиться в `README.md` файле каждой из веток.

### Цель

  Цель этого документа - предоставить исчерпывающее руководство по:
  - запуску и первоначальной настройке ядра сисемы обнаружения объектов;
  - пониманию архитектуры ядра системы обнаружения объектов;
  - развертыванию в различных сценариях и взаимодействии с собственными шлюзами данных.

### Необходимые программы для установки и работы

  - Операционная система: **РЕД ОС 7.3** или **Ubuntu 22.04+**.
  - Среда выполнения: **Docker** для контейнеризации компонентов.
  - **Python 3.10+**.
  - Библиотеки и фреймворки: **FastAPI**, **uvicorn**, **OpenCV**, **FFmpeg**, **ONNXRuntime**.

### Предварительные знания

  Рекомендуется знание Python, принципа работы REST API, а также основ работы с docker образами и контейнерами (из создание и запуск).

## Разделы

### 1. Настройка окружения

  Убедитесь что установлена соответствующая версия Python. Можно возпользоваться встроенным методом для создания окружений **venv**, а можно сторонними: *miniconda, miniforge, anaconda и т.п.*.

  Пример установки и создания окружения, используя **miniforge3**:
  ```
  # Скачивание установочного скрипта
  wget "https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh"

  # Установка (при установке соглашаемся с лицензией и подверждаем что хотим произвести инициализацию сразу)
  bash Miniforge3-$(uname)-$(uname -m).sh

  # Перезапуск терминала
  source ~/.bashrc

  # Создание окружения
  conda create --name <название-окружения> python=<версия-python>

  # Активация окружения
  conda activate <название-окружения>
  ```

### 2. Установка репозитория

  Клонируем репозиторий:
  ```
  git clone Digital-Department-Project
  ```

  Переходим в папку репозитория:
  ```
  cd Digital-Department-Project
  ```

### 3. Установка зависимостей

  Установите все зависимости, необходимые для работы системы обнаружения объектов:

  ```
  pip install -r requirements.txt
  ```

### 4. Конфигурация системы

#### 4.1. Общая конфигурация через конфигурационный файл

  В файле `config/general.json` можно настроить следующие параметры:

  - **manager_port** - порт шлюза связи с сервисом ITX / порт связи сервиса VAS-API. *По умолчанию 5001*;
  - **quality_post_image** - качество JPEG изображения, пересылаемого на сервис VAS-API, которое будет использоваться в отображении в реальном времени. *Диапозон в целочисленных значениях от 0 до 100, по умолчанию 50*. *(Только в интеграции с внутренним сервисом VAS-API)*
  - **framerate** - частота кадров входного видеопотока. Нужен для того, чтобы была возможность менять частоту кадров входного видеопотока (детектор не успевает обрабатывать поток в реальном времени с изначальной частотой, уменьшить частоту кадров для выходного видеоролика или по иным причинам). *Диапозон в целочисленных значениях от 0 до бесконечности (если задать больше исходной частоты кадров, то выставит ее). По умолчанию 10.*
  - **working_time_sec** - время обработки видеопотока (rtsp) в секунундах. То есть сколько секунд будет обрабатываться из предоставленного видеопотока если мы хотим получить в результате видео с нарисованными на нем результатами детекций (обработка не в режиме трансляции). *Диапозон в целочисленных значениях от 0 до бесконечности. По умолчанию 30.* *(Только в интеграции с внутренним сервисом VAS-API)*

  - **tracker_args** - параметры трекера. В словаре описаны различные параметры для трекера. Более подробны описаны в документации по каждому из детекторов. *(В интеграции с сервисом ITX перенесены в отдельный файл tracker.json)*

#### 4.2. Общая конфигурация файла запуска детектора

  В файле `run.sh` указана команда запуска сервера uvicorn c параметрами.
  ```
  uvicorn base_detector:detector.app --reload --port 8000 --host 0.0.0.0 && bash
  ```

  Где сначала указывается название файла, в котором написан код детектора *(в команде выше за это отвечает base_detector)* далее название название объекта класса **FastAPI** *(в команде выше за это отвечает detector.app, так как detector - название объекта класса детектора, app - объекта класса FastAPI)*, после параметр перезапуска сервера, порт, на котором будет запускаться детектор *(по умолчанию 8000)* и адрес *(по умолчанию 0.0.0.0 для того, чтобы до него был доступ со всех сетей, к которым устройство подключено)*. Параметр *&& bash* указан для того, чтобы можно было остановить работу и отладить некоторые вещи прямо в контейнере с детектором.

#### 4.3. Дополнительная конфигурация в файлах с кодом

  Некоторые вещи не вынесены ни в конфигурационные файлы, ни файл запуска в связи с тем что они неразрывно связаны с самим детектором.
  - **Пути до моделей** в файле *(в ядре это `base_detector.py`, в других детекторах отличается)* кода при создании объекта класса указывается путь до файла(ов) модели(ей).
  - **Трешхолды обнаружения объектов** изменяются в файле *(в ядре не изменяются в `base_detector.py`, а находятся в `detector.py`, в других детекторах могут также не изменяться и оставаться по умолчанию)* кода при создании класса.

#### 4.4. Конфигурация логирования

  В файле `logger/config.json` можно настроить логирование:
  - **formatters** - здесь указаны форматы логов;
    - **simple** - менее подробное описание, где указывается только уровень лога и само сообщение;
    - **detailed** - более подробное описание, где также добавляется дата и время лога.
  - **handlers** - здесь описываются обработчики событий;
    - **stderr** - записывает все логи уровня **DEBUG** и выше в stderr (терминал) в формате **simple**.
    - **file** - записывает все логи уровня **INFO** и выше в файл *(по умолчанию в файл `logs/default.log`, но для каждого детектора он меняется на `logs/<название-класса-детектора-в-коде>.log`)* в формате **detailed**. Также указывается максимальный вес одного лог файла в байтах *(по умолчанию 10000000)* и максимальное число этих лог файлов *(по умолчанию 3)*.
    - **error** - записывает все логи уровня **WARNING** и выше в файл *(по умолчанию в файл `logs/errors.log`)* в формате **detailed**. Также указывается максимальный вес одного лог файла в байтах *(по умолчанию 10000000)* и максимальное число этих лог файлов *(по умолчанию 3)*. *(Только в интеграции с сервисом ITX)*
  - **loggers** - здесь описываются все логгеры, а именно логгер **root**.

### 5. Описание изначально пустых/несуществующих папок

  Изначально в директории ядра системе обнаружения целевых объектов находятся пустые папки (могут создаться в процессе работы детектора):
  - **logs** - папка, в которую будут сохраняться все лог-файлы;
  - **models** - папка, в которой должны храниться все файлы моделей нужного детектора;
  - **videos** - папка, в которую будут сохраняться все видео-файлы, полученные в результате обработки. *(Только в интеграции с внутренним сервисом VAS-API)*

### 6. Docker контейнеризация

  Для того, чтобы не скачивать сисетмные и python зависимости каждый раз, можно собрать docker образ и развернуть контейнер. В `Dockerfile` происходит установка всех системных зависимостей, пакетов для FFmpeg, установка самого FFmpeg определенной версии, создание рабочей директории, скачивание и установка python зависимостей, а после и скачивание всего остального кода *(каждый этап описан в самом файле)*.

  Сборка образа:
  ```
  docker build -t detector:base .
  ```

  Очистка лишнего кэша:
  ```
  docker system prune
  ```

  Запуск контейнера, где параметры:
  - **gpus device=0** указывается в том случае, если запускам на видеокарте, а номер - номер видеокарты, взятый из команды **nvidia-smi**;
  - **--restart always** устанавливается для перезапуска контейнера при завершении программы или перезагрузки устройства *(вместо этого для отладки можно использовать **--rm -it**)*;
  - **-v ./logs/:/detector-api/logs/** и **-v ./videos/:/detector-api/** предаставляют доступ к папку внутри контейнера снаружи него;
  - **--network=host** прокидывает все порты наружу контейнера *(вместо этого в некотором случае можно использовать -p 8000:8000)*.
  ```
  docker run --name base-detector -gpus device=0 --restart always -v ./logs/:/detector-api/logs/ -v ./videos/:/detector-api/videos/ --network=host detector:base
  ```

  Подразумевается что изначально собирается образ для ядра системы обнаружения целевых событий, а образы для детекторов, основанных на нем собираются на его основе *(описывается в `README.md` файле в ветках интеграции с сервисом ITX)*.

### 7. API взаимодействия

#### 7.1. Постановка задачи

  - **Method:** POST
  - **Endpoint:** {URL}/api/inference/{id}
  - **Body:**
    - **VAS-API:**
      ```
      {
        "cameraUrls": {
          "video_url": "rtsp://10.4.88.103:8554/example"
        },
        "properties": {
          "isRealtime": False,
          "corners": {
            "cornerUp": 0,
            "cornerLeft": 0,
            "cornerBottom": 1080,
            "cornerRight": 1920
          }
        }
      }
      ```

      - **Примечание:**

        - **"video_url" -** ссылка на поток для распознавания. Также можно указывать путь до файла, расположенного локально. Вместо ссылки на поток может приходить видеофайл для разпознавания, который будет обрабатываться другим способом: заранее сохраняется сохраняется на устройстве и путь до него будет передаваться дальше для распознавания.
        - **"properties" -** параметры, которые задаются через интерфейс *(при отладке не через интерфейс можно не передавать/не указывать в теле)*, среди которых:
          - **"isRealtime"** указывает режим, в котором будет обрабатываться видео (в реальном времени и выдавать поток, либо обрабатывать весь видеофайл/предоставленный поток в течение указанного времени в конфиге) *(задается автоматически)*
          - **corners** обозначают углы зоны интереса, которые задаются в интерфейсе сервиса VAS-API.

    - **SRVR:**
      ```
      {
        "video_url": "rtsp://10.4.88.103:8554/example"
      }
      ```

    - **ANPR:**
      ```
      {
        "video_url": "rtsp://10.4.88.103:8554/example"
      }
      ```

    - **SA:**
      ```
      {
        "video_url": "rtsp://10.4.88.103:8554/example",
        "recognitionAreasSettings": {
          "areas": [
            [
              [0.01, 0.10],
              [0.22, 0.35],
              [0.12, 0.35],
              [0.22, 0.35],
              [0.22, 0.35]
            ],
            [
              [0.20, 0.23],
              [0.81, 0.75],
              [0.22, 0.35],
              [0.12, 0.35]
            ]
          ],
          "maxObjSize": null,
          "minObjSize": 53
        },
        "lineCrossingSettings": {
          "line": [
            [0.22, 0.73],
            [0.82, 0.11]
          ],
          "direction": "any",
          "maxObjSize": null,
          "minObjSize": 53
        }
      }
      ```

      - **Примечание:**

        - **recognitionAreasSettings -** если не передавать в теле запроса, то по умолчанию в качестве зоны интереса будет выбран весь кадр, минимальный размер отправляемого объекта будет равен 0, а максимальный - самое большое допустимое целочисленное число *(sys.maxsize)*.

        - **lineCrossingSettings -** если не передавать в теле запроса, то по умолчанию то будет диагональная линия с координатами **[[0.0, 0.0], [1.0, 1.0]]**, минимальный размер отправляемого объекта будет равен 0, а максимальный - самое большое допустимое целочисленное число *(sys.maxsize)*.

  - **Response:**

    ```
    {
      "task_id": 1,
      "state": 1,
      "success": True,
      "start": 1733991698870,
      "framesProcessed": 0,
      "progress": 0.0,
      "tsLastFrame": 1733991698870
    }
    ```

    - **Примечание:**

      - **task_id** является индификационным номер задачи, который указывается в конце endpoint'а.
      - **state** является состоянием задачи, где:
        - **0 -** инициализация задачи
        - **1 -** задача в работе
        - **2 -** задача остановлена вручную/через DELETE запрос
        - **3 -** задача завершена успешна
        - **4 -** произошла ошибка при выполнении задачи
        - **5 -** зарезервированный статус-код
      - **start** является UNIX like временем *(в милисекундах)* начала работы задачи.
      - **framesProcessed** является количеством уже обработанных кадров.
      - **progress** является прогрессом выполнения задачи в диапозоне от 0 до 1. *(Только в интеграции с внутренним сервисом VAS-API)*
      - **tsLastFrame** является UNIX like временем *(в милисекундах)* последнего обработанного кадра.

  - **Errors:**

    - **405 - задние уже существует**

      Возникает если попытаться создать задание по уже существующему индексу

      - **Response:**

        ```
        {
          "task_id": 1,
          "success": False,
          "state": 1,
        }
        ```

#### 7.2. Получение информации о задаче

  - **Method:** GET
  - **Endpoint:** {URL}/api/inference/{id}
  - **Response:**

    ```
    {
      "task_id": 1,
      "state": 1,
      "success": True,
      "framesProcessed": 10,
      "progress": 0.35,
      "tsLastFrame": 1733992819310
    }
    ```

    - **Примечание:**

      - **task_id** является индификационным номер задачи, который указывается в конце endpoint'а.
      - **state** является состоянием задачи, где:
        - **0 -** инициализация задачи
        - **1 -** задача в работе
        - **2 -** задача остановлена вручную/через DELETE запрос
        - **3 -** задача завершена успешна
        - **4 -** произошла ошибка при выполнении задачи
        - **5 -** зарезервированный статус-код
      - **framesProcessed** является количеством уже обработанных кадров.
      - **progress** является прогрессом выполнения задачи в диапозоне от 0 до 1. *(Только в интеграции с внутренним сервисом VAS-API)*
      - **tsLastFrame** является UNIX like временем *(в милисекундах)* последнего обработанного кадра.

  - **Errors:**

    - **404 - задние не существует**

      Возникает если попытаться получить информацию о задании по несуществующему индексу.

      - **Response:**

        ```
        {
          "detail": "Task not found"
        }
        ```

#### 7.3. Остановка задачи

  - **Method:** DELETE
  - **Endpoint:** {URL}/api/inference/{id}
  - **Response:**

    ```
    {
      "task_id": 1,
      "state": 2,
      "success": True,
      "start": 1733991698870,
      "framesProcessed": 72,
      "tsLastFrame": 1733993061077,
    }
    ```

    - **Примечание:**

      - **task_id** является индификационным номер задачи, который указывается в конце endpoint'а.
      - **state** является состоянием задачи, где:
        - **0 -** инициализация задачи
        - **1 -** задача в работе
        - **2 -** задача остановлена вручную/через DELETE запрос
        - **3 -** задача завершена успешна
        - **4 -** произошла ошибка при выполнении задачи
        - **5 -** зарезервированный статус-код
      - **start** является UNIX like временем *(в милисекундах)* начала работы задачи.
      - **framesProcessed** является количеством уже обработанных кадров.
      - **progress** является прогрессом выполнения задачи в диапозоне от 0 до 1. *(Только в интеграции с внутренним сервисом VAS-API)*
      - **tsLastFrame** является UNIX like временем *(в милисекундах)* последнего обработанного кадра.

  - **Errors:**

    - **404 - задние не существует**

      Возникает если попытаться удалить задание по несуществующему индексу.

      - **Response:**

        ```
        {
          "detail": "Task not found"
        }
        ```

### 8. Путь работы задачи

  - Приходит **POST** запрос, который запускает работу детектора;
  - В фоновом процессе запускается метод **_perform_inference**, в который передаются все нужные данные из тела запроса;
  - Он запускает цикличный метод **_inference_cycle**, в который также передаются все нужные данные для обработки;
  - В нем происходит подготовка всех данных и работа основного цикла. В цикле кадры обрабатываются детектором, проходят проверку, и если после нее данные остаются, то они отправляются в метод **send_results**.
  - Этот метод вычленяет нужные данные из результатов обработки детектора, преобразует их в нужный вид и перенаправляет в менеджер *(шлюз данных между детекторами и сервисом ITX/сервис VAS-API)*.
