{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rb6cAkE29KTx"
      },
      "outputs": [],
      "source": [
        "# Before running this code in Google Colab, upload the following files:\n",
        "# 1. best.pt: Weights of the fine-tuned YOLOv8n model trained on the MOT17.\n",
        "# 2. Sample.mp4: A trimmed sample video from the MOT17 dataset.\n",
        "# 3. SFSORT.py: The tracking algorithm file.\n",
        "\n",
        "# After running the code, an output video named 'output.mp4' will be generated.\n",
        "# This video is a processed version of 'Sample.mp4' and displays bounding boxes\n",
        "# and unique IDs for each detected object (people)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83BVcok5oGAG",
        "outputId": "9cc3f543-93db-45d7-eb45-80739575cec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lapx\n",
            "  Downloading lapx-0.5.11-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from lapx) (1.26.4)\n",
            "Downloading lapx-0.5.11-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lapx\n",
            "Successfully installed lapx-0.5.11\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.25-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.10-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.25-py3-none-any.whl (878 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m878.7/878.7 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.10-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.25 ultralytics-thop-2.0.10\n"
          ]
        }
      ],
      "source": [
        "# Install lapx, required for SFSORT\n",
        "!pip install lapx\n",
        "\n",
        "#Install ultralytics to access the object detector\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6fYxYHZo5MX",
        "outputId": "84a7563b-df50-4846-966e-c65867c160ba"
      },
      "outputs": [],
      "source": [
        "# Import essential libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.torch_utils import select_device\n",
        "from random import randrange\n",
        "\n",
        "from SFSORT import SFSORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model = YOLO('best.pt', 'detect')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.78 üöÄ Python-3.10.12 torch-2.6.0+cu124 CPU (Intel Core(TM) i5-10210U 1.60GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 1440, 1440) BCHW and output shape(s) (1, 5, 42525) (6.1 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16.0/16.0 MB 11.4 MB/s eta 0:00:00\n",
            "Collecting onnxslim\n",
            "  Downloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 142.9/142.9 KB 17.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.20 in /home/yuichi-katagiri/yuichi_env/lib/python3.10/site-packages (from onnx>=1.12.0) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /home/yuichi-katagiri/yuichi_env/lib/python3.10/site-packages (from onnx>=1.12.0) (5.29.3)\n",
            "Requirement already satisfied: packaging in /home/yuichi-katagiri/yuichi_env/lib/python3.10/site-packages (from onnxslim) (24.1)\n",
            "Requirement already satisfied: sympy in /home/yuichi-katagiri/yuichi_env/lib/python3.10/site-packages (from onnxslim) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/yuichi-katagiri/yuichi_env/lib/python3.10/site-packages (from sympy->onnxslim) (1.3.0)\n",
            "Installing collected packages: onnx, onnxslim\n",
            "Successfully installed onnx-1.17.0 onnxslim-0.1.48\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 7.2s, installed 2 packages: ['onnx>=1.12.0', 'onnxslim']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 8.7s, saved as 'best.onnx' (12.3 MB)\n",
            "\n",
            "Export complete (10.0s)\n",
            "Results saved to \u001b[1m/home/yuichi-katagiri/[MAIN]/OUTDOOR/Digital-Department-Project/MAIN/SFSORT\u001b[0m\n",
            "Predict:         yolo predict task=detect model=best.onnx imgsz=1440  \n",
            "Validate:        yolo val task=detect model=best.onnx imgsz=1440 data=/content/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ],
      "source": [
        "model = model.export(format = 'onnx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.onnx \n",
        "\n",
        "#Function to Convert to ONNX \n",
        "def Convert_ONNX(): \n",
        "\n",
        "    # set the model to inference mode \n",
        "    model.eval() \n",
        "\n",
        "    # Let's create a dummy input tensor  \n",
        "    dummy_input = torch.rand(1, 3, 640, 640,  requires_grad=True)  \n",
        "\n",
        "    # Export the model   \n",
        "    torch.onnx.export(model,         # model being run \n",
        "         dummy_input,       # model input (or a tuple for multiple inputs) \n",
        "         \"ImageClassifier.onnx\",       # where to save the model  \n",
        "         export_params=True,  # store the trained parameter weights inside the model file \n",
        "         opset_version=11,    # the ONNX version to export the model to \n",
        "         do_constant_folding=True) \n",
        "    print(\" \") \n",
        "    print('Model has been converted to ONNX')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING ‚ö†Ô∏è torch.Tensor inputs should be BCHW i.e. shape(1, 3, 640, 640) divisible by stride 32. Input shape(3, 800, 1440) is incompatible.\n",
            "0: 800x1440 (no detections), 394.8ms\n",
            "Speed: 1.6ms preprocess, 394.8ms inference, 12.8ms postprocess per image at shape (1, 3, 800, 1440)\n"
          ]
        }
      ],
      "source": [
        "something = model.predict(torch.rand(1, 3, 640, 640))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.79 available üòÉ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.78 üöÄ Python-3.10.12 torch-2.6.0+cu124 CPU (Intel Core(TM) i5-10210U 1.60GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=best.pt, data=/content/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=1440, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Dataset '/content/data.yaml' error ‚ùå '/content/data.yaml' does not exist",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/ultralytics/engine/trainer.py:564\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    563\u001b[0m }:\n\u001b[0;32m--> 564\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/ultralytics/data/utils.py:316\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03mDownload, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    (dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/ultralytics/utils/checks.py:522\u001b[0m, in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[0;32m--> 522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: '/content/data.yaml' does not exist",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mConvert_ONNX\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mConvert_ONNX\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m,  requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Export the model   \u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# model being run \u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# model input (or a tuple for multiple inputs) \u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImageClassifier.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# where to save the model  \u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# store the trained parameter weights inside the model file \u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m     \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the ONNX version to export the model to \u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel has been converted to ONNX\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/torch/onnx/__init__.py:383\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining, **_)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_shapes:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe exporter only supports dynamic shapes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthrough parameter dynamic_axes when dynamo=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    381\u001b[0m     )\n\u001b[0;32m--> 383\u001b[0m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/torch/onnx/utils.py:495\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;241m+\u001b[39m (kwargs,)\n\u001b[0;32m--> 495\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/torch/onnx/utils.py:1405\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, (torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule)):\n\u001b[1;32m   1401\u001b[0m     module_typenames_to_export_as_functions \u001b[38;5;241m=\u001b[39m _setup_trace_module_map(\n\u001b[1;32m   1402\u001b[0m         model, export_modules_as_functions\n\u001b[1;32m   1403\u001b[0m     )\n\u001b[0;32m-> 1405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m exporter_context(model, training, verbose):\n\u001b[1;32m   1406\u001b[0m     val_keep_init_as_ip \u001b[38;5;241m=\u001b[39m _decide_keep_init_as_input(\n\u001b[1;32m   1407\u001b[0m         keep_initializers_as_inputs,\n\u001b[1;32m   1408\u001b[0m         operator_export_type,\n\u001b[1;32m   1409\u001b[0m         opset_version,\n\u001b[1;32m   1410\u001b[0m     )\n\u001b[1;32m   1411\u001b[0m     val_add_node_names \u001b[38;5;241m=\u001b[39m _decide_add_node_names(\n\u001b[1;32m   1412\u001b[0m         add_node_names, operator_export_type\n\u001b[1;32m   1413\u001b[0m     )\n",
            "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/torch/onnx/utils.py:147\u001b[0m, in \u001b[0;36mexporter_context\u001b[0;34m(model, mode, verbose)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexporter_context\u001b[39m(model, mode: _C_onnx\u001b[38;5;241m.\u001b[39mTrainingMode, verbose: \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m select_model_mode_for_export(\n\u001b[1;32m    148\u001b[0m         model, mode\n\u001b[1;32m    149\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m mode_ctx, disable_apex_o2_state_dict_hook(\n\u001b[1;32m    150\u001b[0m         model\n\u001b[1;32m    151\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m apex_ctx, setup_onnx_logging(\n\u001b[1;32m    152\u001b[0m         verbose\n\u001b[1;32m    153\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m log_ctx, diagnostics\u001b[38;5;241m.\u001b[39mcreate_export_diagnostic_context() \u001b[38;5;28;01mas\u001b[39;00m diagnostic_ctx:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (mode_ctx, apex_ctx, log_ctx, diagnostic_ctx)\n",
            "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/torch/onnx/utils.py:92\u001b[0m, in \u001b[0;36mselect_model_mode_for_export\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m     90\u001b[0m         model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m _C_onnx\u001b[38;5;241m.\u001b[39mTrainingMode\u001b[38;5;241m.\u001b[39mEVAL:\n\u001b[0;32m---> 92\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# else mode == _C_onnx.TrainingMode.PRESERVE, do nothing\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/ultralytics/engine/model.py:804\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    802\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[0;32m--> 804\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/ultralytics/engine/trainer.py:134\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
            "File \u001b[0;32m~/yuichi_env/lib/python3.10/site-packages/ultralytics/engine/trainer.py:568\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ‚ùå \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset '/content/data.yaml' error ‚ùå '/content/data.yaml' does not exist"
          ]
        }
      ],
      "source": [
        "Convert_ONNX()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN3bWNxCpGOn",
        "outputId": "b86f98c7-250b-4d89-b3c8-924c06db041f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.25 üöÄ Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "YOLO(\n",
              "  (model): DetectionModel(\n",
              "    (model): Sequential(\n",
              "      (0): Conv(\n",
              "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (2): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): Conv(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (4): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): Conv(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (6): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): Conv(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (8): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): SPPF(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (11): Concat()\n",
              "      (12): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (14): Concat()\n",
              "      (15): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (16): Conv(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (17): Concat()\n",
              "      (18): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (19): Conv(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (20): Concat()\n",
              "      (21): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0): Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (22): Detect(\n",
              "        (cv2): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (cv3): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (dfl): DFL(\n",
              "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instantiate an object detector\n",
        "# To use YOLOv8n without fine-tuning, replace 'best.pt' with 'yolov8n.pt'\n",
        "model = YOLO('best.pt', 'detect')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = select_device('0')\n",
        "# Devolve the processing to selected devices\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oeaBk-vkpQXT"
      },
      "outputs": [],
      "source": [
        "# Load the video file\n",
        "cap = cv2.VideoCapture('/content/Sample.mp4')\n",
        "\n",
        "# Get the frame rate, frame width, and frame height\n",
        "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the MP4 codec and create a VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output.mp4', fourcc, 30.0, (frame_width, frame_height))\n",
        "\n",
        "# Organize tracker arguments into standard format\n",
        "tracker_arguments = {\"dynamic_tuning\": True, \"cth\": 0.5,\n",
        "                      \"high_th\": 0.6, \"high_th_m\": 0.1,\n",
        "                      \"match_th_first\": 0.67, \"match_th_first_m\": 0.05,\n",
        "                      \"match_th_second\": 0.2, \"low_th\": 0.1,\n",
        "                      \"new_track_th\": 0.7, \"new_track_th_m\": 0.1,\n",
        "                      \"marginal_timeout\": (7 * frame_rate // 10),\n",
        "                      \"central_timeout\": frame_rate,\n",
        "                      \"horizontal_margin\": frame_width // 10,\n",
        "                      \"vertical_margin\": frame_height // 10,\n",
        "                      \"frame_width\": frame_width,\n",
        "                      \"frame_height\": frame_height}\n",
        "\n",
        "# Instantiate a tracker\n",
        "tracker = SFSORT(tracker_arguments)\n",
        "\n",
        "# Define a color list for track visualization\n",
        "colors = {}\n",
        "\n",
        "# Process each frame of the video\n",
        "while cap.isOpened():\n",
        "   # Load the frame\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "      break\n",
        "\n",
        "  # Detect people in the frame\n",
        "  prediction = model.predict(frame, imgsz=(800,1440), conf=0.1, iou=0.45,\n",
        "                              half=False, device=device, max_det=99, classes=0,\n",
        "                              verbose=False)\n",
        "\n",
        "  # Exclude additional information from the predictions\n",
        "  prediction_results = prediction[0].boxes.cpu().numpy()\n",
        "\n",
        "  # Update the tracker with the latest detections\n",
        "  tracks = tracker.update(prediction_results.xyxy, prediction_results.conf)\n",
        "\n",
        "  # Skip additional analysis if the tracker is not currently tracking anyone\n",
        "  if len(tracks) == 0:\n",
        "      continue\n",
        "\n",
        "  # Extract tracking data from the tracker\n",
        "  bbox_list = tracks[:, 0]\n",
        "  track_id_list = tracks[:, 1]\n",
        "\n",
        "  # Visualize tracks\n",
        "  for idx, (track_id, bbox) in enumerate(zip(track_id_list, bbox_list)):\n",
        "    # Define a new color for newly detected tracks\n",
        "    if track_id not in colors:\n",
        "        colors[track_id] = (randrange(255), randrange(255), randrange(255))\n",
        "\n",
        "    color = colors[track_id]\n",
        "\n",
        "    # Extract the bounding box coordinates\n",
        "    x0, y0, x1, y1 = map(int, bbox)\n",
        "\n",
        "    # Draw the bounding boxes on the frame\n",
        "    annotated_frame = cv2.rectangle(frame, (x0, y0), (x1, y1), color, 2)\n",
        "    # Put the track label on the frame alongside the bounding box\n",
        "    cv2.putText(annotated_frame, str(track_id), (x0, y0-5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "\n",
        "\n",
        "  # Write the frame to the output video file\n",
        "  out.write(annotated_frame)\n",
        "\n",
        "# Release everything when done\n",
        "cap.release()\n",
        "out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "yuichi_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
